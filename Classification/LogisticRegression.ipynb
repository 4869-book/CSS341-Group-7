{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befde9b7-2f25-4627-bec3-0ce109f98ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import talib as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1227f3f-2028-44a4-b465-1de3a35a4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "def evaluate_model(dt_classifier):\n",
    "    print(\"Train Accuracy :\", accuracy_score(y_train, dt_classifier.predict(X_train)))\n",
    "    print(\"Train Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_train, dt_classifier.predict(X_train)))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Test Accuracy :\", accuracy_score(y_test, dt_classifier.predict(X_test)))\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, dt_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1d63da-a1b0-40f2-9636-fb9c0afed812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv file \n",
    "#Dataset A\n",
    "HSI_4y = pd.read_csv('../dataset/^HSI_4y.csv')\n",
    "N225_4y = pd.read_csv('../dataset/^N225_4y.csv')\n",
    "SSE_4y = pd.read_csv('../dataset/000001.SS_4y.csv')\n",
    "DJI_4y = pdr.get_data_yahoo(\"^DJI\", start=\"2012-01-01\", end=\"2016-12-31\").reset_index() #Nikkei 225\n",
    "\n",
    "#Dataset B\n",
    "HSI_7y = pd.read_csv('../dataset/^HSI_7y.csv')\n",
    "N225_7y = pd.read_csv('../dataset/^N225_7y.csv')\n",
    "SSE_7y = pd.read_csv('../dataset/000001.SS_7y.csv')\n",
    "DJI_7y = pdr.get_data_yahoo(\"^DJI\", start=\"2012-01-01\", end=\"2019-12-31\").reset_index()#Nikkei 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efc4445-664a-4f12-9c44-613ddb7476dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1258 entries, 0 to 1257\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   High       1258 non-null   float64\n",
      " 1   Low        1258 non-null   float64\n",
      " 2   Open       1258 non-null   float64\n",
      " 3   Close      1258 non-null   float64\n",
      " 4   Volume     1258 non-null   int64  \n",
      " 5   Adj Close  1258 non-null   float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 68.8 KB\n"
     ]
    }
   ],
   "source": [
    "#chose the data\n",
    "df = DJI_4y\n",
    "df = df.drop(columns=['Date']).dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77becd3d-910d-4c50-a1c3-f41510550bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Technical indicator\n",
    "close = df['Close'].values\n",
    "high = df['High'].values\n",
    "low = df['Low'].values\n",
    "volume = df['Volume'].values.astype(float)\n",
    "#Simple movingaverage (SMA)\n",
    "df['SMA5'] = tl.SMA(close, timeperiod=5)\n",
    "df['SMA10'] = tl.SMA(close, timeperiod=10)\n",
    "df['SMA14'] = tl.SMA(close, timeperiod=14)\n",
    "df['SMA30'] = tl.SMA(close, timeperiod=30)\n",
    "\n",
    "#Exponentialmoving average\n",
    "df['EMA5'] = tl.EMA(close, timeperiod=5)\n",
    "df['EMA10'] = tl.EMA(close, timeperiod=10)\n",
    "df['EMA14'] = tl.EMA(close, timeperiod=14)\n",
    "df['EMA30'] = tl.EMA(close, timeperiod=30)\n",
    "\n",
    "#Momentum indicator\n",
    "df['MOM5'] = tl.MOM(close, timeperiod=5)\n",
    "df['MOM10'] = tl.MOM(close, timeperiod=10)\n",
    "df['MOM14'] = tl.MOM(close, timeperiod=14)\n",
    "\n",
    "#Moving average convergence divergence\n",
    "df['MACD'], df['MACDSIGNAL'], df['macdhist'] = tl.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "#Stochastic oscillator\n",
    "df['STOCHK'], df['STOCHD'] = tl.STOCH(high, low, close, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "\n",
    "#Relative strength index\n",
    "df['RSI14'] = tl.RSI(close, timeperiod=14)\n",
    "df['RSI28'] = tl.RSI(close, timeperiod=28)\n",
    "\n",
    "#Williams R\n",
    "df['WILLR14'] = tl.WILLR(high, low, close, timeperiod=14)\n",
    "df['WILLR28'] = tl.WILLR(high, low, close, timeperiod=28)\n",
    "\n",
    "#Accumulation distribution index\n",
    "df['AD']= tl.AD(high, low, close, volume)\n",
    "\n",
    "\n",
    "#Commodity channel index\n",
    "df['CCI14'] = tl.CCI(high, low, close, timeperiod=14)    \n",
    "df['CCI28'] = tl.CCI(high, low, close, timeperiod=28)    \n",
    "\n",
    "#Rate of change \n",
    "df['ROC'] = tl.ROC(close, timeperiod=2)\n",
    "\n",
    "#Average True Range\n",
    "df['ATR'] = tl.ATR(high, low, close, timeperiod=14)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc29166-5db4-4428-85dd-333c21d34645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Target column\n",
    "df['Target'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)\n",
    "df['Target2'] = np.where(100*((df['Close'].shift(-1)-df['Open'])/df['Open']) > 0 , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e2af80-f7e5-40b1-81a9-a2951803b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 25)\n",
      "(1225,)\n"
     ]
    }
   ],
   "source": [
    "#Split the data set into the a feature or indipendent data set (X) and a Target or dependant data set (Y)\n",
    "keep_columns = df.drop(['High','Low','Open','Volume','Adj Close','macdhist','Target','Target2'],axis=1).columns\n",
    "X = df[keep_columns].values\n",
    "y = df['Target2'].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "271235b9-5601-4a91-9de0-d844634d14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "\n",
    "#StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "394a3baf-9d39-46f2-9bd6-adf588c294e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "estimator = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e778383-479c-4a6d-8dd0-35a54591e279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Feature selection\n",
    "#use RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(estimator, n_features_to_select=5, step=1)\n",
    "rfe = rfe.fit(X, y)\n",
    "X_new = rfe.fit_transform(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c78a40-fa57-4582-93bf-8152fe4588be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split test train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "527beefd-69d6-466c-89f0-bbd1f917e054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "GridSearchCV(cv=4, estimator=LogisticRegression(), n_jobs=-1,\n",
      "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01], 'penalty': ['l2'],\n",
      "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
      "             scoring='accuracy', verbose=1)\n",
      "LogisticRegression(C=100, solver='newton-cg')\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2'],\n",
    "    'C': [100, 10, 1.0, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=estimator, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "print(grid_search.fit(X_train, y_train))\n",
    "print(grid_search.best_estimator_)\n",
    "rf_best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "436e9299-204d-4a0a-9504-7dcb46f68700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.6974063400576369\n",
      "Train Confusion Matrix:\n",
      "[[244 206]\n",
      " [109 482]]\n",
      "--------------------------------------------------\n",
      "Test Accuracy : 0.6847826086956522\n",
      "Test Confusion Matrix:\n",
      "[[44 41]\n",
      " [17 82]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398dcf1-f89b-48d4-b1e9-84e316bd7ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
